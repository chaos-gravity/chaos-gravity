<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chaos万有引力</title>
    <description>We are interested in Deep Learning, Machine Learning, Causality, Reinforcement Learning, and any other information or technologies about AI.</description>
    <link>https://chaos-gravity.github.io/</link>
    <atom:link href="https://chaos-gravity.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 03 Aug 2020 18:51:45 +0800</pubDate>
    <lastBuildDate>Mon, 03 Aug 2020 18:51:45 +0800</lastBuildDate>
    <generator>Jekyll v3.8.7</generator>
    
      <item>
        <title>Cross Entropy Loss</title>
        <description>&lt;p&gt;&lt;strong&gt;交叉熵&lt;/strong&gt;度量的是两个概率分布的差异。&lt;/p&gt;

&lt;p&gt;要理解交叉熵，有很多小概念需要理解。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息量&lt;/strong&gt;，一个事件发生的概率越大，事件发生携带的信息量越小，发生的概率越小，事件发生携带的信息量越大。比如太阳从东边升起，这个事件如果发生了，我们可以从这个事件中获得的信息几乎是没有的。但是，如果哪天太阳从西边升起了，那么我们从这个事件中获得的信息量是极大的，一定发生了什么，或者即将发生什么，才造成了这个事件发生。&lt;/p&gt;

&lt;p&gt;假设X是一个离散型随机变量，概率分布函数为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_005.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;则定义&lt;em&gt;X&lt;/em&gt; = &lt;em&gt;x&lt;/em&gt;0事件发生携带的信息量为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_011.png&quot; alt=&quot;AltText&quot; width=&quot;27%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;若&lt;em&gt;p&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;0)为0，也就是事件&lt;em&gt;x&lt;/em&gt;0是不可能发生的事件，但是它却发生了，那么这个事件的信息量是无穷大的，&lt;em&gt;I&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;0)的值无穷大，如果&lt;em&gt;p&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;0)为1，也就是事件&lt;em&gt;x&lt;/em&gt;0是一定会发生的事件，那么这个事件的发生是不带信息量的，&lt;em&gt;I&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;0)的值是0。&lt;/p&gt;

&lt;p&gt;另外，信息量可以这样理解 [2]：&lt;/p&gt;

&lt;p&gt;Information quantifies the number of bits required to encode and transmit an event.&lt;/p&gt;

&lt;p&gt;信息量可以被理解为，传输或表达这个信息需要的编码的位数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息熵&lt;/strong&gt;，则是信息量的期望值：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_007.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考[3]里给了一个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_010.png&quot; alt=&quot;AltText&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每次开电脑，都可能会产生三种状况，电脑正常开机的概率是0.7，电脑无法开机的概率是0.2，电脑爆炸的概率是0.1。那么每次开机，得到的信息量的的期望值是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_006.png&quot; alt=&quot;AltText&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果是二项分布，那么信息熵的计算可以简化为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_002.png&quot; alt=&quot;AltText&quot; width=&quot;55%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;事件的概率不均，信息熵较小，若各个事件发生的概率一样，信息熵较大。&lt;/p&gt;

&lt;p&gt;信息熵在[2]中的描述为：&lt;/p&gt;

&lt;p&gt;Entropy is the number of bits required to transmit a randomly selected event from a probability distribution.&lt;/p&gt;

&lt;p&gt;熵是表达或者传输一个遵循特定概率分布的随机事件需要的位数，个人觉得the number of应该改成the average number of，位数前面应该有个平均，和期望的概念对应上。但也可能是我哪里理解错了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相对熵&lt;/strong&gt;(&lt;strong&gt;relative entropy&lt;/strong&gt;)，又称之为KL散度(Kullback-Leibler (KL) divergence)，公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_008.png&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;相对熵的目标是：计算用&lt;em&gt;P&lt;/em&gt;描述目标问题，比&lt;em&gt;Q&lt;/em&gt;描述目标问题能获得的信息增量。&lt;/p&gt;

&lt;p&gt;如果分布&lt;em&gt;P&lt;/em&gt;和分布&lt;em&gt;Q&lt;/em&gt;是一样的，那么相对熵是0，如果不一样，相对熵大于0，越大，表示两种分布之间的差距越大。&lt;/p&gt;

&lt;p&gt;在机器学习的项目中，通常&lt;em&gt;P&lt;/em&gt;表示真实的分布，即需要训练模型达到的分布，&lt;em&gt;Q&lt;/em&gt;是现在用的模型预测的分布。&lt;/p&gt;

&lt;p&gt;相对熵在参考[2]中的描述是：&lt;/p&gt;

&lt;p&gt;In other words, the KL divergence is the average number of extra bits  needed to encode the data, due to the fact that we used distribution q  to encode the data instead of the true distribution p.&lt;/p&gt;

&lt;p&gt;— Page 58, Machine Learning: A Probabilistic Perspective, 2012.&lt;/p&gt;

&lt;p&gt;交叉熵是，当我们用分布q来替代事件真实遵循的分布p时，传输和表达事件时，比使用分布p多需要的平均位数。也就是q是我们用的分布，p是事件真实遵循的分布，用q的话，比用p需要更多的位数来表达和传输这个事件，平均多多少呢，交叉熵就是这个多出来的多少。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;交叉熵&lt;/strong&gt;(&lt;strong&gt;Cross entropy&lt;/strong&gt;)，将相对熵公式变形：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_009.png&quot; alt=&quot;AltText&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前半部分是信息熵的负值，后半部分则是交叉熵，交叉熵的公式是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640.png&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因为&lt;em&gt;P&lt;/em&gt;的信息熵是一定的，那么其实是可以省略这部分计算的，交叉熵和相对熵的意义是一样的。只是最后计算出的值，区间不一样。&lt;/p&gt;

&lt;p&gt;交叉熵在参考[2]中的描述是：&lt;/p&gt;

&lt;p&gt;…, the cross entropy is the average number of bits needed to encode data  coming from a source with distribution p when we use model q, …
  — Page 57, Machine Learning: A Probabilistic Perspective, 2012&lt;/p&gt;

&lt;p&gt;交叉熵是当你用模型q来预测分布p时，表达和传输事件需要的平均位数。&lt;/p&gt;

&lt;p&gt;以下定义来自参考[2]，俺就不翻了:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cross-Entropy&lt;/strong&gt;: Average number of total bits to represent an event from Q instead of P.
&lt;strong&gt;Relative Entropy&lt;/strong&gt; (&lt;em&gt;KL Divergence&lt;/em&gt;): Average number of extra bits to represent an event from Q instead of P.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cross-Entropy Loss 和 Softmax Loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;毫无疑问，交叉熵可以用作损失函数，且比起MSE，MAE，要优秀不少，&lt;/p&gt;

&lt;p&gt;… using the cross-entropy error function instead of the sum-of-squares  for a classification problem leads to faster training as well as  improved generalization. — Page 235, Pattern Recognition and Machine Learning, 2006.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640.jpeg&quot; alt=&quot;AltText&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;结合上面猫狗分类的案例，假如有一张猫图输入，&lt;em&gt;P&lt;/em&gt;是[1, 0], &lt;em&gt;Q&lt;/em&gt;是[0.71, 0.29]，交叉熵的计算为：&lt;/p&gt;

&lt;p&gt;H(P, Q) = – (P(cat) * log(Q(cat)) + P(dog) * log(Q(dog)))&lt;/p&gt;

&lt;p&gt;值得注意的是，在很多多分类问题中，不论有多少类，P不论有多少个元素，都只有一个为1，其他都为0，所以交叉熵的计算可以化简，也就是说如果P(cat)为1，那么交叉熵的结果和Q(dog)，Q(car)，Q(any other)是无关的：&lt;/p&gt;

&lt;p&gt;H(P, Q) = – log(Q(cat))&lt;/p&gt;

&lt;p&gt;因此，如果Q(cat)是用&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247483971&amp;amp;idx=1&amp;amp;sn=41b7cf6139bb0cae6c3ad926bf223147&amp;amp;chksm=c0676081f710e997397f6ee38eda67be9e39ad02ceb27c865059a0c972909a8c7c439fd80b34&amp;amp;scene=21#wechat_redirect&quot;&gt;Softmax&lt;/a&gt; Function计算出来的，那么H(P, Q)计算得到的就是该样本在该模型下的Softmax Loss。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247483971&amp;amp;idx=1&amp;amp;sn=41b7cf6139bb0cae6c3ad926bf223147&amp;amp;chksm=c0676081f710e997397f6ee38eda67be9e39ad02ceb27c865059a0c972909a8c7c439fd80b34&amp;amp;scene=21#wechat_redirect&quot;&gt;Softmax&lt;/a&gt; Function专门有一篇：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247483971&amp;amp;idx=1&amp;amp;sn=41b7cf6139bb0cae6c3ad926bf223147&amp;amp;chksm=c0676081f710e997397f6ee38eda67be9e39ad02ceb27c865059a0c972909a8c7c439fd80b34&amp;amp;scene=21#wechat_redirect&quot;&gt;Softmax&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Softmax Loss&lt;/strong&gt;的完整公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_003.png&quot; alt=&quot;AltText&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;N是样本数量，n是class的数量，特征向量的长度为&lt;em&gt;d&lt;/em&gt;，&lt;em&gt;Wj&lt;/em&gt;是&lt;em&gt;W&lt;/em&gt;的第&lt;em&gt;j&lt;/em&gt;列，和&lt;em&gt;b&lt;/em&gt;一起是获得特征向量的全连接层，&lt;em&gt;W&lt;/em&gt;是&lt;em&gt;d*n&lt;/em&gt;，&lt;em&gt;bj&lt;/em&gt;的长度是&lt;em&gt;n&lt;/em&gt;。log后面则是用Softmax Function计算出的‘Q(cat)’。&lt;/p&gt;

&lt;p&gt;因此，其实本来没有什么Softmax Loss的概念，这个公式是在多分类任务中使用Softmax Function+Cross Entropy loss产生的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cross Entropy Loss 和 Log Loss [4]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;她俩在解决二分类问题的时候，其实是一回事，不服气的看公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Cross_Entropy_Loss/640_004.png&quot; alt=&quot;AltText&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个公式既叫Binary Cross-Entropy，也叫Log Loss，y是label，p(y)是预测结果，符号和之前的公式没有一一对应，看的时候注意一下。&lt;/p&gt;

&lt;p&gt;Log Loss的推导基于最大似然估计(Maximum Likelihood)和伯努利分布(Bernoulli distribution)，有机会写一篇。&lt;/p&gt;

&lt;p&gt;那么&lt;strong&gt;Cross Entropy的值&lt;/strong&gt;为多少时，表示预测的结果还挺准确的呢？这里参考[2]给了个一些参考，具体问题还要具体分析。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cross-Entropy = 0.00&lt;/strong&gt;: Perfect probabilities.
 &lt;strong&gt;Cross-Entropy &amp;lt; 0.02&lt;/strong&gt;: Great probabilities.
 &lt;strong&gt;Cross-Entropy &amp;lt; 0.05&lt;/strong&gt;: On the right track.
 &lt;strong&gt;Cross-Entropy &amp;lt; 0.20&lt;/strong&gt;: Fine.
 &lt;strong&gt;Cross-Entropy &amp;gt; 0.30&lt;/strong&gt;: Not great.
 &lt;strong&gt;Cross-Entropy &amp;gt; 1.00&lt;/strong&gt;: Terrible.
 &lt;strong&gt;Cross-Entropy &amp;gt; 2.00&lt;/strong&gt; Something is broken.&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1] Thomas Wood，Softmax Function Definition, DeepAI&lt;/p&gt;

&lt;p&gt;[2] Jason Brownlee，A Gentle Introduction to Cross-Entropy for Machine Learning，2019&lt;/p&gt;

&lt;p&gt;[3] 史丹利复合田，一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉，CSDN，2018&lt;/p&gt;

&lt;p&gt;[4] Daniel Godoy, Understanding binary cross-entropy / log loss: a visual explanation, Towards Data Science, 2018&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Aug 2020 00:00:00 +0800</pubDate>
        <link>https://chaos-gravity.github.io/cross-entropy-loss/</link>
        <guid isPermaLink="true">https://chaos-gravity.github.io/cross-entropy-loss/</guid>
        
        
        <category>Loss Function</category>
        
      </item>
    
      <item>
        <title>Softmax</title>
        <description>&lt;p&gt;​		Softmax，这个概念参考[1]解释的非常仔细，这里只做简述，先上公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_eq&quot; alt=&quot;AltText&quot; width=&quot;35%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这公式是啥子意思呢？先看一个应用：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax&quot; alt=&quot;AltText&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​		假如我们现在有一个分类任务，如果模型足够理想，输入一张猫图，输出[1, 0]，输入一张狗图，输出[0,  1]。通常这种任务，前面会是一个深度卷积神经网络，最后会有一个全连接层，经过这个全连接层会得到图的特征向量(embedding)，我自己喜欢管embedding叫特征向量。上图中最后得到的特征向量是[1.2, 0.3]，再经过softmax：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_007&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;得到了[0.71,  0.29]，我们可以这样理解最后这个结果，这张图是猫的概率是0.71，是狗的概率是0.29，它们两加起来是1，不管softmax的输入向量为何，输出向量里的值相加一定是1，得到的结果可以理解为图在各个类上的概率分布，向量的长度即类别（class）的数量。再以一个长度为3的一维向量为例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_009&quot; alt=&quot;AltText&quot; width=&quot;10%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设你现在要训练一个模型，它需要有能力分辨猫，狗，鸟，你模型训练好以后，输入了一张鸟图，得到了一个这样的特征向量，现在要做softmax，计算步骤如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_006&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_004&quot; alt=&quot;AltText&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_005&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​		所以按模型判断，该图是鸟图的概率是0.0003，明显这个模型不准诶。&lt;/p&gt;

&lt;p&gt;​		softmax还可用于&lt;strong&gt;增强学习&lt;/strong&gt;（reinforcement learning），先上公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_reinforcement&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​		在机器视觉领域，softmax的输出，是图像在各个类别上的概率分布，在增强学习领域，softmax的输出可以是各个策略的在某个步骤或时间会被采取的可能性。公式中&lt;em&gt;a&lt;/em&gt;是我们可以选的行动，&lt;em&gt;t&lt;/em&gt;表示的是步骤或者时间，τ是系统温度，这个值越高，模型越冲动，越会去探索新的可能。qt(a)是从现在已知的情况来看，选择行动a会获得成功的概率，Pt(a)则是模型在t这个步骤或时间上会采取a行动的概率。&lt;/p&gt;

&lt;p&gt;​		想象一下，我们正在训练一种强化学习模型。我们必须配置一个系统温度τ，它是系统随机行动的可能性。该系统目前有两个选项：打Ace或打King。根据过往经验，打Ace成功的概率是80％，打King成功的概率是20％。我们将温度τ配置为2。&lt;/p&gt;

&lt;p&gt;​		那么在这一轮中，模型打Ace的概率是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Softmax/softmax_008&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​		这意味着尽管该模型目前有80％的把握确定打Ace是正确的策略，但只有57％的可能性使用该策略。这是因为在强化学习中，我们为探索（测试新策略）和开发（使用已知策略）均分配了价值。如果我们提高温度，则该模型将变得“更具冲动性”：更有可能探索新策略，而不是使用最有可能获胜的策略。&lt;/p&gt;

&lt;p&gt;声明：图文，案例均来自参考，本篇仅是翻译和摘要。&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1] Thomas Wood，Softmax Function Definition, DeepAI&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Jul 2020 00:00:00 +0800</pubDate>
        <link>https://chaos-gravity.github.io/Softmax/</link>
        <guid isPermaLink="true">https://chaos-gravity.github.io/Softmax/</guid>
        
        
        <category>Loss Function</category>
        
      </item>
    
      <item>
        <title>Hello, World!</title>
        <description>&lt;p&gt;现在是2020年2月22日，总觉得该做点什么。&lt;/p&gt;

&lt;p&gt;不如敲行python代码吧！&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;print(&quot;Hello, World!&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;来日方长，请多关照！&lt;/p&gt;

</description>
        <pubDate>Sat, 22 Feb 2020 00:00:00 +0800</pubDate>
        <link>https://chaos-gravity.github.io/HelloWorld/</link>
        <guid isPermaLink="true">https://chaos-gravity.github.io/HelloWorld/</guid>
        
        
        <category>HelloWorld</category>
        
      </item>
    
  </channel>
</rss>
